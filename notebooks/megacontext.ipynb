{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7fb27b941602401d91542211134fc71a",
      "metadata": {},
      "source": [
        "# MegaContext Research Console\n",
        "\n",
        "Interactively prepare datasets, train GistNet with PyTorch Lightning, and capture experiment artifacts. Key docs: [GistNet](https://brandf.github.io/MegaContext/architecture/components/GistNet), [GistNet Training](https://brandf.github.io/MegaContext/architecture/components/GistNet%20Training), [Telemetry](https://brandf.github.io/MegaContext/ops/Telemetry), [Alternating Optimization](https://brandf.github.io/MegaContext/ops/Alternating%20Optimization).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Start\n",
        "\n",
        "When running in Google Colab, execute the bootstrap cell below to clone the repo and install dependencies in the current runtime. Local Jupyter environments can skip it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "COLAB = 'google.colab' in sys.modules\n",
        "if COLAB:\n",
        "    repo_url = 'https://github.com/brandf/MegaContext.git'\n",
        "    workspace = Path('/content/MegaContext')\n",
        "    if not workspace.exists():\n",
        "        !git clone $repo_url $workspace\n",
        "    else:\n",
        "        !git -C $workspace pull --ff-only\n",
        "    %cd /content/MegaContext\n",
        "    print('Python executable:', sys.executable)\n",
        "    %pip install --upgrade pip\n",
        "    %pip install -r requirements.txt\n",
        "    %pip install -e .\n",
        "    %pip install pytorch-lightning lightning\n",
        "    !python -m pip show pytorch-lightning lightning\n",
        "    src_path = workspace / 'src'\n",
        "    if str(src_path) not in sys.path:\n",
        "        sys.path.append(str(src_path))\n",
        "    importlib.invalidate_caches()\n",
        "    try:\n",
        "        import megacontext  # noqa: F401\n",
        "        import lightning  # noqa: F401\n",
        "    except Exception as exc:\n",
        "        print('Import check failed:', exc)\n",
        "        raise\n",
        "    else:\n",
        "        print('Colab environment ready.')\n",
        "else:\n",
        "    print('Colab bootstrap skipped (not running in google.colab).')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acae54e37e7d407bbb7b55eff062a284",
      "metadata": {},
      "source": [
        "## 0. Environment Snapshot\n",
        "\n",
        "Verify your runtime (GPU, dependencies, disk space) before launching long jobs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a63283cbaf04dbcab1f6479b197f3a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import yaml\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "from megacontext.notebook import (\n",
        "    MetricsTracker,\n",
        "    build_logger,\n",
        "    collect_environment_report,\n",
        "    format_config_markdown,\n",
        "    format_dataset_summary,\n",
        "    format_training_config,\n",
        "    format_training_summary,\n",
        "    render_environment_report,\n",
        "    save_experiment_summary,\n",
        ")\n",
        "\n",
        "ENV_REPORT = collect_environment_report()\n",
        "display(Markdown(render_environment_report(ENV_REPORT)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dd0d8092fe74a7c96281538738b07e2",
      "metadata": {},
      "source": [
        "## 1. Choose Experiment Config\n",
        "\n",
        "Use the dropdown to select a combined config (dataset + base model + training).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72eea5119410473aa328ad9291626812",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    import ipywidgets as widgets\n",
        "except ImportError:\n",
        "    widgets = None\n",
        "\n",
        "CONFIG_ROOT = Path('configs')\n",
        "available_configs = sorted(CONFIG_ROOT.glob('*.yaml'))\n",
        "if not available_configs:\n",
        "    raise RuntimeError('No experiment configs found under `configs/`.')\n",
        "\n",
        "config_table = pd.DataFrame(\n",
        "    [{'name': path.stem, 'path': str(path)} for path in available_configs]\n",
        ")\n",
        "display(config_table)\n",
        "\n",
        "if widgets is None:\n",
        "    print('ipywidgets not available; defaulting to the first config.')\n",
        "    EXPERIMENT_CONFIG = available_configs[0]\n",
        "else:\n",
        "    buttons = []\n",
        "    message_box = widgets.Output()\n",
        "\n",
        "    def make_handler(path: Path):\n",
        "        def _handler(_):\n",
        "            globals()['EXPERIMENT_CONFIG'] = path\n",
        "            with message_box:\n",
        "                message_box.clear_output()\n",
        "                display(Markdown(f\"Selected **{path.stem}** (`{path}`)\"))\n",
        "        return _handler\n",
        "\n",
        "    for cfg_path in available_configs:\n",
        "        button = widgets.Button(\n",
        "            description=f\"Use {cfg_path.stem}\",\n",
        "            layout=widgets.Layout(width='180px')\n",
        "        )\n",
        "        button.on_click(make_handler(cfg_path))\n",
        "        buttons.append(button)\n",
        "\n",
        "    button_row = widgets.HBox(buttons)\n",
        "    display(button_row, message_box)\n",
        "    globals()['EXPERIMENT_CONFIG'] = available_configs[0]\n",
        "    with message_box:\n",
        "        message_box.clear_output()\n",
        "        display(Markdown(f\"Defaulting to **{available_configs[0].stem}** (`{available_configs[0]}`)\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8edb47106e1a46a883d545849b8ab81b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "try:\n",
        "    import ipywidgets as widgets\n",
        "except ImportError:\n",
        "    widgets = None\n",
        "\n",
        "LOGGER_STATE = {'selection': 'none', 'project': 'megacontext-poc', 'run_name': ''}\n",
        "\n",
        "if 'EXPERIMENT_CONFIG' not in globals():\n",
        "    from pathlib import Path\n",
        "    CONFIG_ROOT = Path('configs')\n",
        "    configs = sorted(CONFIG_ROOT.glob('*.yaml'))\n",
        "    if not configs:\n",
        "        raise RuntimeError('No experiment configs found under `configs/`.')\n",
        "    EXPERIMENT_CONFIG = configs[0]\n",
        "\n",
        "if widgets is None:\n",
        "    print('ipywidgets not available; logging defaults to disabled.')\n",
        "else:\n",
        "    logger_dropdown = widgets.Dropdown(\n",
        "        options=[('Disabled', 'none'), ('Weights & Biases', 'wandb')],\n",
        "        value='none',\n",
        "        description='Logger:',\n",
        "        layout=widgets.Layout(width='50%'),\n",
        "    )\n",
        "    project_text = widgets.Text(\n",
        "        value=LOGGER_STATE['project'],\n",
        "        description='Project:',\n",
        "        layout=widgets.Layout(width='50%'),\n",
        "    )\n",
        "    run_text = widgets.Text(\n",
        "        value=LOGGER_STATE['run_name'],\n",
        "        placeholder='auto',\n",
        "        description='Run name:',\n",
        "        layout=widgets.Layout(width='50%'),\n",
        "    )\n",
        "    wandb_box = widgets.VBox([project_text, run_text])\n",
        "    wandb_box.layout.display = 'none'\n",
        "\n",
        "    def _update_logger_state(_):\n",
        "        LOGGER_STATE['selection'] = logger_dropdown.value\n",
        "        LOGGER_STATE['project'] = project_text.value\n",
        "        LOGGER_STATE['run_name'] = run_text.value\n",
        "        wandb_box.layout.display = (\n",
        "            'flex' if LOGGER_STATE['selection'] == 'wandb' else 'none'\n",
        "        )\n",
        "\n",
        "    for widget in (logger_dropdown, project_text, run_text):\n",
        "        widget.observe(_update_logger_state, names='value')\n",
        "    _update_logger_state(None)\n",
        "\n",
        "    summary = widgets.HTML(\n",
        "        value=f\"<b>Config:</b> {EXPERIMENT_CONFIG.stem} (<code>{EXPERIMENT_CONFIG}</code>)\"\n",
        "    )\n",
        "    display(summary, widgets.VBox([logger_dropdown, wandb_box]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10185d26023b46108eb7d9f57d49d2b3",
      "metadata": {},
      "source": [
        "## 2. Preview Configuration\n",
        "\n",
        "Review and, if needed, edit fields before running stages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8763a12b2bbd4a93a75aff182afb95dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment_cfg = yaml.safe_load(EXPERIMENT_CONFIG.read_text(encoding='utf-8'))\n",
        "display(Markdown(format_config_markdown(experiment_cfg)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7623eae2785240b9bd12b16a66d81610",
      "metadata": {},
      "source": [
        "## 3. Dataset Preparation\n",
        "\n",
        "Runs `tools.prepare_dataset.prepare_dataset_from_config` with tqdm progress bars. Skip this if the shard already exists.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cdc8c89c7104fffa095e18ddfef8986",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from tools.prepare_dataset import load_dataset_config, prepare_dataset_from_config\n",
        "\n",
        "DATASET_RESULT = prepare_dataset_from_config(EXPERIMENT_CONFIG)\n",
        "display(Markdown(format_dataset_summary(DATASET_RESULT['splits'])))\n",
        "SPLIT_NAME = 'train'\n",
        "dataset_cfg_model = load_dataset_config(EXPERIMENT_CONFIG)\n",
        "split_cfg = dataset_cfg_model.splits[SPLIT_NAME]\n",
        "output_path_cfg = Path(split_cfg.output_path)\n",
        "if output_path_cfg.is_absolute():\n",
        "    DATASET_PATH = output_path_cfg\n",
        "else:\n",
        "    base_dir = EXPERIMENT_CONFIG.parent\n",
        "    default_output = (base_dir / output_path_cfg).resolve()\n",
        "    data_root_override = (\n",
        "        Path(os.environ['MEGACONTEXT_DATA_ROOT']).expanduser().resolve()\n",
        "        if 'MEGACONTEXT_DATA_ROOT' in os.environ\n",
        "        else None\n",
        "    )\n",
        "    if data_root_override is not None:\n",
        "        resolved_base = base_dir.resolve()\n",
        "        repo_root = (\n",
        "            resolved_base.parents[1]\n",
        "            if len(resolved_base.parents) >= 2\n",
        "            else resolved_base\n",
        "        )\n",
        "        try:\n",
        "            relative = default_output.relative_to(repo_root)\n",
        "        except ValueError:\n",
        "            relative = default_output.name\n",
        "        DATASET_PATH = (data_root_override / relative).resolve()\n",
        "    else:\n",
        "        DATASET_PATH = default_output\n",
        "DATASET_RESULT['dataset_path'] = str(DATASET_PATH)\n",
        "DATASET_RESULT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b118ea5561624da68c537baed56e602f",
      "metadata": {},
      "source": [
        "### Sample Example\n",
        "\n",
        "Peek at the first prepared context to sanity-check tokens and horizons.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "938c804e27f84196a10c8828c723f798",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyarrow.ipc as pa_ipc\n",
        "\n",
        "if not Path(DATASET_PATH).exists():\n",
        "    missing_msg = (\n",
        "        f\"Dataset shard not found at {DATASET_PATH}. \"\n",
        "        \"Run the prep cell first.\"\n",
        "    )\n",
        "    raise FileNotFoundError(missing_msg)\n",
        "reader = pa_ipc.open_file(DATASET_PATH)\n",
        "if reader.num_record_batches == 0:\n",
        "    print('Dataset is empty.')\n",
        "else:\n",
        "    batch = reader.get_batch(0)\n",
        "    row = batch.to_pydict()\n",
        "    context_tokens = row['context_input_ids'][0][:32]\n",
        "    future_tokens = row['future_input_ids'][0][:16]\n",
        "    summary_html = (\n",
        "        f\"Context tokens (first 32): {context_tokens}<br><br>\"\n",
        "        f\"Future tokens (first 16): {future_tokens}\"\n",
        "    )\n",
        "    display(Markdown(summary_html))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "504fb2a444614c0babb325280ed9130a",
      "metadata": {},
      "source": [
        "## 4. Configure GistNet Training\n",
        "\n",
        "Hidden size defaults to the teacher embedding width reported during dataset prep (set `gistnet.model.hidden_size` explicitly to override).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59bbdb311c014d738909a11f9e486628",
      "metadata": {},
      "outputs": [],
      "source": [
        "import dataclasses\n",
        "from copy import deepcopy\n",
        "\n",
        "from megacontext.gistnet import BaseModelSettings, GistNetConfig, GistNetTrainingConfig\n",
        "\n",
        "dataset_hidden_size = DATASET_RESULT['splits'][SPLIT_NAME]['teacher_hidden_size']\n",
        "gistnet_cfg = experiment_cfg.get('gistnet', {})\n",
        "model_dict = deepcopy(gistnet_cfg.get('model', {}))\n",
        "if model_dict.get('hidden_size') == 'auto':\n",
        "    if dataset_hidden_size:\n",
        "        model_dict['hidden_size'] = dataset_hidden_size\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            'Dataset summary did not report a teacher hidden size; '\n",
        "            'set gistnet.model.hidden_size explicitly.'\n",
        "        )\n",
        "MODEL_CONFIG = GistNetConfig(**model_dict)\n",
        "\n",
        "training_dict = deepcopy(gistnet_cfg.get('training', {}))\n",
        "TRAINING_CONFIG = GistNetTrainingConfig.from_dict(training_dict)\n",
        "if TRAINING_CONFIG.base_model is None and 'base_model' in experiment_cfg:\n",
        "    TRAINING_CONFIG = dataclasses.replace(\n",
        "        TRAINING_CONFIG,\n",
        "        base_model=BaseModelSettings.from_dict(experiment_cfg['base_model']),\n",
        "    )\n",
        "display(Markdown(format_training_config(TRAINING_CONFIG)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b43b363d81ae4b689946ece5c682cd59",
      "metadata": {},
      "source": [
        "### Optional Overrides\n",
        "\n",
        "Adjust batch size or per-phase learning rates/steps without editing YAML.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a65eabff63a45729fe45fb5ade58bdc",
      "metadata": {},
      "outputs": [],
      "source": [
        "if widgets is None:\n",
        "    print(\n",
        "        'ipywidgets not available; use dataclasses.replace(...) to '\n",
        "        'override training settings manually.'\n",
        "    )\n",
        "else:\n",
        "    batch_slider = widgets.IntSlider(\n",
        "        value=TRAINING_CONFIG.batch_size,\n",
        "        min=1,\n",
        "        max=128,\n",
        "        step=1,\n",
        "        description='Batch size:',\n",
        "    )\n",
        "    log_every_slider = widgets.IntSlider(\n",
        "        value=max(1, TRAINING_CONFIG.log_every_n_steps),\n",
        "        min=1,\n",
        "        max=max(1, TRAINING_CONFIG.log_every_n_steps * 2),\n",
        "        step=1,\n",
        "        description='Log every:',\n",
        "    )\n",
        "    phase_widgets = []\n",
        "    for phase in TRAINING_CONFIG.phases:\n",
        "        steps_slider = widgets.IntSlider(\n",
        "            value=phase.max_steps,\n",
        "            min=1,\n",
        "            max=max(phase.max_steps, 100),\n",
        "            step=1,\n",
        "            description='Steps',\n",
        "        )\n",
        "        lr_slider = widgets.FloatLogSlider(\n",
        "            value=phase.lr,\n",
        "            base=10,\n",
        "            min=-6,\n",
        "            max=0,\n",
        "            step=0.1,\n",
        "            description='LR',\n",
        "        )\n",
        "        window_slider = widgets.IntSlider(\n",
        "            value=phase.window_tokens,\n",
        "            min=MODEL_CONFIG.block_size,\n",
        "            max=max(phase.window_tokens, MODEL_CONFIG.block_size * 64),\n",
        "            step=MODEL_CONFIG.block_size,\n",
        "            description='Window',\n",
        "        )\n",
        "        phase_box = widgets.VBox([\n",
        "            widgets.HTML(f'<b>{phase.name}</b> ({phase.objective})'),\n",
        "            steps_slider,\n",
        "            lr_slider,\n",
        "            window_slider,\n",
        "        ])\n",
        "        phase_widgets.append((phase, phase_box))\n",
        "    apply_button = widgets.Button(description='Apply overrides', button_style='success')\n",
        "    overrides_output = widgets.Output()\n",
        "\n",
        "    def _apply_overrides(_):\n",
        "        global TRAINING_CONFIG\n",
        "        phases = []\n",
        "        for base_phase, phase_box in phase_widgets:\n",
        "            steps_slider, lr_slider, window_slider = phase_box.children[1:]\n",
        "            phases.append(\n",
        "                dataclasses.replace(\n",
        "                    base_phase,\n",
        "                    max_steps=int(steps_slider.value),\n",
        "                    lr=float(lr_slider.value),\n",
        "                    window_tokens=int(window_slider.value),\n",
        "                )\n",
        "            )\n",
        "        TRAINING_CONFIG = dataclasses.replace(\n",
        "            TRAINING_CONFIG,\n",
        "            batch_size=int(batch_slider.value),\n",
        "            log_every_n_steps=int(log_every_slider.value),\n",
        "            phases=tuple(phases),\n",
        "        )\n",
        "        overrides_output.clear_output()\n",
        "        with overrides_output:\n",
        "            display(\n",
        "                Markdown(\n",
        "                    format_training_config(\n",
        "                        TRAINING_CONFIG, heading='Updated Training Config'\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "\n",
        "    apply_button.on_click(_apply_overrides)\n",
        "    controls = widgets.VBox(\n",
        "        [batch_slider, log_every_slider]\n",
        "        + [box for _, box in phase_widgets]\n",
        "        + [apply_button, overrides_output]\n",
        "    )\n",
        "    display(controls)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3933fab20d04ec698c2621248eb3be0",
      "metadata": {},
      "source": [
        "## 5. Build Lightning Components\n",
        "\n",
        "Adds a rich progress bar and metrics tracker; enable WandB above to stream logs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dd4641cc4064e0191573fe9c69df29b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightning.pytorch.callbacks import RichProgressBar  # type: ignore\n",
        "\n",
        "from megacontext.gistnet import build_gistnet_experiment\n",
        "\n",
        "metrics_callback = MetricsTracker(metric_keys=(\n",
        "    'train/loss',\n",
        "    'train/delta_loss',\n",
        "    'train/gist_loss',\n",
        "    'train/baseline_loss',\n",
        "))\n",
        "callbacks = [metrics_callback, RichProgressBar()]\n",
        "LOGGER = None\n",
        "try:\n",
        "    LOGGER = build_logger(\n",
        "        selection=LOGGER_STATE.get('selection', 'none'),\n",
        "        project=LOGGER_STATE.get('project'),\n",
        "        run_name=LOGGER_STATE.get('run_name'),\n",
        "        config={'config_path': str(EXPERIMENT_CONFIG)},\n",
        "    )\n",
        "except RuntimeError as exc:\n",
        "    print(exc)\n",
        "\n",
        "TRAINER, MODULE, DATA_MODULE = build_gistnet_experiment(\n",
        "    dataset_path=DATASET_PATH,\n",
        "    model_config=MODEL_CONFIG,\n",
        "    training=TRAINING_CONFIG,\n",
        "    callbacks=callbacks,\n",
        "    logger=LOGGER,\n",
        "    trainer_kwargs={\n",
        "        'accelerator': 'auto',\n",
        "        'devices': 1,\n",
        "        'default_root_dir': './artifacts/gistnet',\n",
        "    },\n",
        ")\n",
        "TRAINER\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8309879909854d7188b41380fd92a7c3",
      "metadata": {},
      "source": [
        "## 6. Launch Training\n",
        "\n",
        "Run this cell to start the Lightning loop. Progress appears below and (optionally) in WandB.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ed186c9a28b402fb0bc4494df01f08d",
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAINER.fit(MODULE, DATA_MODULE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb1e1581032b452c9409d6c6813c49d1",
      "metadata": {},
      "source": [
        "## 7. Visualise Metrics\n",
        "\n",
        "Plots the captured metrics (requires matplotlib).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379cbbc1e968416e875cc15c1202d7eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics_callback.plot(figsize=(7, 4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "277c27b1587741f2af2001be3712ef0d",
      "metadata": {},
      "source": [
        "## 8. Summarise & Save\n",
        "\n",
        "Captures final metrics and writes a JSON summary under `artifacts/experiments/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db7b79bc585a40fcaf58bf750017e135",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "final_metrics = {k: float(v) for k, v in TRAINER.callback_metrics.items()}\n",
        "display(Markdown(format_training_summary(final_metrics)))\n",
        "SUMMARY_PATH = save_experiment_summary(\n",
        "    output_dir=Path('artifacts/experiments'),\n",
        "    config_path=EXPERIMENT_CONFIG,\n",
        "    dataset_summary=DATASET_RESULT['splits'],\n",
        "    training_metrics=final_metrics,\n",
        "    artifacts={\n",
        "        'dataset_path': DATASET_RESULT.get('dataset_path'),\n",
        "        'default_root_dir': TRAINER.default_root_dir,\n",
        "    },\n",
        ")\n",
        "SUMMARY_PATH\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
