---
tags:
  - plans
  - prd
summary: End-to-end MegaContext training roadmap aligning GistNet, LensNet, and the base LLM within a unified optimization loop.
---
# MegaContext: End-to-End Training Strategy

This document describes the end-to-end training procedure for [[MegaContext]], integrating [[GistNet]], [[LensNet]], the frozen base LLM, and lightweight [[LoRA]] adapters into a unified optimization loop. The objective is to co-train summarization, focus, and decoding so the system learns how to **summarize**, **focus**, and **reason** with compressed context.

Terminology: **LOD0** = raw tokens, **LOD1** = 32→1 gists, **LOD2** = 32 LOD1 gists (1024→1), etc.

---

## Motivation

Early MegaContext prototypes trained [[GistNet]], [[LensNet]], and base-model adapters sequentially. That approach caused:
- **Distribution shift:** each component optimized against stale inputs.
- **Weak coupling:** improvements in one module did not propagate to the others.
- **Wasted compute:** repeated forward passes yielded no joint gradient signal.

End-to-end training aligns all modules under a single next-token objective so that [[GistNet]], [[LensNet]], the [[Focus Allocator]], and the base LLM co-adapt during each step of [[Alternating Optimization]].

---

## End-to-End Training Flow

Each training sequence (context `C`) is transformed into many [[Working Context|working contexts]] (WCs) that mix LOD0 tokens with [[GistNet]] summaries (LOD1, LOD2). These candidates are scored, compared, and refined jointly:

```
Full training context C (≈4k tokens)
 ├── Build full [[MegaContext Tree]] with GistNet summaries (LOD1, LOD2, …)
 ├── Sample N1 WCs of length C2 (≈1k tokens)
 │    ├── Always include a WC containing the C2 most recent LOD0 tokens
 │    └── Sample diverse mixes of LOD0/LOD1/LOD2 spans under the token budget
 ├── Run LensNet + Focus Allocator on each WC → expand to N2 refined WCs
 │    ├── Allow up to four expand/collapse edits per iteration
 │    └── Inject sibling perturbations for additional ΔNLL labels
 ├── Evaluate base model on all N2 WCs (teacher-forced horizon H)
 │    ├── Compute ΔNLL@H for token substitutions
 │    └── Backpropagate through GistNet + base LLM (LoRA adapters only)
 └── Update LensNet with ΔNLL supervision
      ├── Identify ideal WC(s) via regularized argmin
      └── Derive target focus scores for the Focus Allocator
```

---

## Detailed Procedure

### Step 1. Build the MegaContext Tree
- **Input:** tokenized training context `C`.
- **Goal:** produce multi-level summaries using [[GistNet]] (LOD1 = 32→1, LOD2 = 32 LOD1 → 1).
- **Output:** hierarchical [[MegaContext Tree]] cached for reuse by all downstream steps.

### Step 2. Sample Working Contexts (`N1`)
- **Goal:** create `N1` diverse WCs of length `C2` (e.g., 1k tokens).
- **Baseline WC:** the `C2` most recent LOD0 tokens.
- **Diversity sampler:** draw additional WCs using varied combinations of {LOD0, LOD1, LOD2, …}, penalizing near-duplicate layouts to avoid myopic policies.

### Step 3. LensNet Expansion and Focus Allocation (`N2`)
- Run [[LensNet]] on each WC to produce span utilities.
- Apply the [[Focus Allocator]] with up to four expand/collapse actions, observing budget, contiguity, and cooldown invariants.
- Generate `N2` refined WCs, including sibling perturbations for richer ΔNLL labels, and deduplicate to retain unique layouts.

### Step 4. Teacher-Forced Evaluation

Each WC is evaluated for next-token accuracy over a short horizon `H`, keeping the WC fixed (no refocusing):

#### Teacher forcing primer
- Feed the WC (LOD0/LOD1/LOD2 mix) into the base LLM.
- Predict the next `H` ground-truth tokens using teacher forcing (real tokens provided at every step).
- Average the resulting NLL to obtain the horizon loss.

#### Efficient horizon loss computation
You do **not** need iterative rollouts:
- **Packed forward (preferred):** concatenate `[WC || H ground-truth tokens]`, run a single forward pass, and compute loss only on the final `H` positions. This leverages kernels like [[Flash Attention]].
- **Incremental with KV cache:** precompute KV once for the WC, then step through `H` positions reusing the cache. Use when the packed sequence would exceed memory.

Backpropagation flows through the base model (LoRA layers) and any [[GistNet]] projections involved in the WC.

### Step 5. Gist Auxiliary Losses
Augment token loss with gist-level objectives:

1. **LOD1 regression:** for every 32-token block within the horizon, compare:
   - `g_true = GistNet(embed(block_tokens))`
   - `g_pred = GistNet(softmax(logits_block) @ token_embeddings)`
   Use cosine distance or MSE and weight with coefficient `α1`.

2. **LOD2 regression (optional):** when `H = 1024`, stack 32 LOD1 gists and repeat the process with a smaller coefficient `α2`.

These losses run in tandem with token NLL, encouraging semantic fidelity across levels of detail.

### Step 6. LensNet ΔNLL Supervision
- Use horizon ΔNLL deltas to label hypothetical expand/collapse actions for each WC.
- Apply a regularized argmin to choose target WCs, balancing utility gains and policy stability.
- Train [[LensNet]] with regression, ranking, budget, and legality losses exactly as outlined in [[LensNet Training]].

### Step 7. Iterate with Alternating Optimization
- Repeat Steps 1–6 following the JT1/JT2/JT3 schedule in [[Alternating Optimization]].
- Checkpoint after each phase and refresh ΔNLL labels whenever [[GistNet]] or [[LensNet]] changes materially.

### Step 8. Validation Checkpoints
Run structured validation on held-out traces:
- ΔNLL@H ≤ 0.1 at the target `W_max`.
- Swap rate ≤ 0.25 actions/block.
- Mean residency ≥ 3 iterations/span.
- Latency overhead ≤ 10% relative to the frozen base LLM.

---

## Losses and Backpropagation Scope

| Loss term | Definition | Backprop targets |
|-----------|------------|------------------|
| `L_token` | Cross-entropy over final `H` positions | Base LLM (LoRA layers) |
| `L_lod1`  | Cosine/MSE between predicted vs. ground-truth LOD1 gists | [[GistNet]] |
| `L_lod2`  | Cosine/MSE over 1024-token gists (optional) | [[GistNet]] |
| `L_focus` | ΔNLL-driven utilities for span edits | [[LensNet]], [[Focus Allocator]] heuristics |

Total loss: `L_total = L_token + α1·L_lod1 + α2·L_lod2 + λ_focus·L_focus`.

---

## Why This Design Works

| Design choice | Benefit |
|---------------|---------|
| Regularized argmin | Stabilizes focus targets by preferring consistent improvements. |
| ΔNLL supervision | Directly ties focus changes to measured utility over the base model’s loss landscape. |
| Constant budget | Forces the system to trade detail rather than simply increase token count. |
| WC diversity | Prevents recency-only policies and encourages exploration of alternative focus layouts. |
| Gist losses | Preserve semantics when substituting LOD1/LOD2 summaries in the [[Working Context]]. |
| Packed horizon | Efficiently captures multi-step effects without costly rollouts. |

---

## Key Hyperparameters

| Symbol | Meaning | Typical value |
|--------|---------|---------------|
| `N1` | Number of sampled WCs | 8–32 |
| `N2` | Number of refined WCs | 32–128 |
| `C2` | WC token budget | 512–2048 |
| `H` | Teacher-forced horizon | 32–64 initially; 128–256 later; 1024 for LOD2 |
| `λ` | Argmin stability weight | 0.1–0.3 |
| `α1` | LOD1 loss weight | 0.01–0.05 |
| `α2` | LOD2 loss weight | 0.005–0.02 |

---

## Pseudocode (Horizon + Gist Losses)

```python
for wc in refined_working_contexts:
    seq = concat(wc, gt_tokens[:H])
    logits = base_model(seq)  # packed forward
    token_loss = nll(logits[-H:], gt_tokens[:H])

    if H % 32 == 0:
        gt_blocks = chunk(gt_tokens[:H], size=32)
        pred_probs = logits[-H:].softmax(dim=-1)
        pred_embeds = pred_probs @ token_embedding_matrix
        pred_blocks = chunk(pred_embeds, size=32)

        gt_lod1 = [gistnet(embed(block)) for block in gt_blocks]
        pred_lod1 = [gistnet(block) for block in pred_blocks]
        lod1_loss = cosine_distance(pred_lod1, gt_lod1).mean()

    if H == 1024:
        gt_lod2 = gistnet(torch.stack(gt_lod1))
        pred_lod2 = gistnet(torch.stack(pred_lod1))
        lod2_loss = cosine_distance(pred_lod2, gt_lod2)

    total = token_loss + alpha1 * lod1_loss + alpha2 * lod2_loss
    total.backward()
```

---

## Expected Dynamics

- **Early cycles:** LOD0-only WCs dominate; [[GistNet]] focuses on substitutability; LOD1 loss stabilizes semantic fidelity.
- **Mid cycles:** Mixed WCs outperform pure LOD0; [[LensNet]] discovers high-utility spans; ΔNLL refinements sharpen expansion decisions.
- **Late cycles:** Focus patterns stabilize; occasional LOD2 loss enforces global consistency; ΔNLL remains ≤ 0.1 at fixed compute.

---

## Summary

End-to-end training introduces efficient horizon scoring, multi-level gist regression, and ΔNLL-driven focus targets that let MegaContext adaptively manage detail while keeping compute and memory fixed. The result is a synchronized pipeline where [[GistNet]] carries substitutable summaries, [[LensNet]] steers the [[Focus Allocator]], and small [[LoRA]] adapters align the base LLM with mixed-LOD inputs.
